{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90086 Workshop 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, you will have some practice of color manipulation and canny edge detection. We will also verify the installed software for the next week's workshop.\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "- Color\n",
    "    - Colour space transformations\n",
    "    - Colour manipulations\n",
    "    \n",
    "- Edge\n",
    "    - Canny edge detection step by step\n",
    "\n",
    "- Verify softare for the next week\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Colour space transformations\n",
    "\n",
    "### <center>RGB(red/green/blue) vs. HSV(Hue/Saturation/Value)</center>\n",
    "\n",
    "<img style=\"float: left ;\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/RGB_color_solid_cube.png/1920px-RGB_color_solid_cube.png\" width=300 height=300>\n",
    "\n",
    "(Image Source: Wikipedia)\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://929687.smushcdn.com/2407837/wp-content/uploads/2021/04/opencv_color_spaces_rgb_additive.png?lossy=1&strip=1&webp=0\" width=300 height=300>\n",
    "\n",
    "(Image Source: These images appears in many places, including [here](https://929687.smushcdn.com/2407837/wp-content/uploads/2021/04/opencv_color_spaces_rgb_additive.png?lossy=1&strip=1&webp=0))\n",
    "\n",
    "<img style=\"float: ;\" src=\"https://upload.wikimedia.org/wikipedia/commons/3/33/HSV_color_solid_cylinder_saturation_gray.png\" width=300 height=300>\n",
    "\n",
    "(Image Source: Wikipedia)\n",
    "\n",
    "\n",
    "### <center>RGB(device-dependent) vs. XYZ (device-independent)</center>\n",
    "\n",
    "<center>The CIE XYZ standard observer color matching functions </center>\n",
    "\n",
    "<img style=\"float: ;\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/8f/CIE_1931_XYZ_Color_Matching_Functions.svg\" width=300 height=300>\n",
    "\n",
    "(Image Source: Wikipedia)\n",
    "\n",
    "### <center>Lab</center>\n",
    "\n",
    "L*: The lightness value, defines black at 0 (down) and white at 100 (up), with neutral grays at the center of the axis. \n",
    "\n",
    "The a* axis represents the green–red opponent, with negative values toward green and positive values toward red. \n",
    "\n",
    "The b* axis represents the blue–yellow opponents, with negative numbers toward blue and positive toward yellow.\n",
    "\n",
    "In theory there are no maximum values of a* and b*, but in practice they are usually numbered from -128 to +127 (256 levels).\n",
    "\n",
    "<img style=\"float: ;\" src=\"https://929687.smushcdn.com/2407837/wp-content/uploads/2021/04/opencv_color_spaces_lab_sphere.png?lossy=1&strip=1&webp=0\" width=300 height=300>\n",
    "\n",
    "(Image Source: These images appears in many places, including [here](https://929687.smushcdn.com/2407837/wp-content/uploads/2021/04/opencv_color_spaces_lab_sphere.png?lossy=1&strip=1&webp=0))\n",
    "\n",
    "[Color conversions Explanation](https://docs.opencv.org/4.6.0/de/d25/imgproc_color_conversions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2  \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[cv2.IMREAD_UNCHANGED](https://docs.opencv.org/4.6.0/d8/d6a/group__imgcodecs__flags.html#gga61d9b0126a3e57d9277ac48327799c80aeddd67043ed0df14f9d9a4e66d2b0708): It is used to read the image as it is. It does not make any changes or ignore anything from the image. You can also specify -1 for this flag.\n",
    "\n",
    "[cv2.cvtColor( )](https://docs.opencv.org/4.6.0/d8/d01/group__imgproc__color__conversions.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath='./'\n",
    "img = cv2.imread(os.path.join(rootpath, \"kodim23.png\"),cv2.IMREAD_UNCHANGED ) #BGR\n",
    "\n",
    "#rearrange the channel for showing image\n",
    "img1 = np.zeros(img.shape,np.uint8)\n",
    "img1[:,:,0] = img[:,:,2] #red\n",
    "img1[:,:,1] = img[:,:,1] #green\n",
    "img1[:,:,2] = img[:,:,0] #blue\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.title('original image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "img_cvt = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "#rearrange the channel for showing image\n",
    "img2 = np.zeros(img_cvt.shape,np.uint8)\n",
    "img2[:,:,0] = img_cvt[:,:,2] #red\n",
    "img2[:,:,1] = img_cvt[:,:,1] #green\n",
    "img2[:,:,2] = img_cvt[:,:,0] #blue\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.title('hsv converted image')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "- Transform RGB to XYZ color space and show each channel.\n",
    "- Transform XYZ back to RGB, and show the final image ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transform RGB to LAB colorspace and show each channel.\n",
    "- Transform LAB back to RGB, and show the final image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Colour manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath = './'\n",
    "img = cv2.imread(os.path.join(rootpath, \"kodim23.png\"),cv2.IMREAD_UNCHANGED ) #BGR\n",
    "\n",
    "#rearrange the channel for showing image\n",
    "img1 = np.zeros(img.shape,np.uint8)\n",
    "img1[:,:,0] = img[:,:,2] #red\n",
    "img1[:,:,1] = img[:,:,1] #green\n",
    "img1[:,:,2] = img[:,:,0] #blue\n",
    "\n",
    "img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "#swap a b channel for showing difference\n",
    "img_lab2 = np.zeros(img_lab.shape,np.uint8)\n",
    "img_lab2[:,:,0] = img_lab[:,:,0] \n",
    "img_lab2[:,:,1] = img_lab[:,:,2] \n",
    "img_lab2[:,:,2] = img_lab[:,:,1]\n",
    "\n",
    "img_cvt = cv2.cvtColor(img_lab2, cv2.COLOR_Lab2BGR)\n",
    "\n",
    "#rearrange the channel for showing image\n",
    "img2 = np.zeros(img_cvt.shape,np.uint8)\n",
    "img2[:,:,0] = img_cvt[:,:,2] #red\n",
    "img2[:,:,1] = img_cvt[:,:,1] #green\n",
    "img2[:,:,2] = img_cvt[:,:,0] #blue\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(img1)\n",
    "plt.title('original image')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(img2)\n",
    "plt.title('swap ab channel in lab ')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "- Transform to LAB, invert the `a` axis, then back transform to RGB. Show the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  (1) Canny edge detection step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the image using OpenCV with grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath='./'\n",
    "org_img = cv2.imread(os.path.join(rootpath, \"cannyimg.png\"),cv2.IMREAD_GRAYSCALE )\n",
    "org_img = org_img.astype(float)\n",
    "\n",
    " \n",
    "plt.imshow(org_img ,cmap='gray')  \n",
    "plt.title('original image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find edge magnitude and orientation (Gradient Calculation)\n",
    "- Edges are points in the image with a high change in intensity = high change in gradient.\n",
    "- Accurate edge detection requires smoothing image noise.\n",
    "- Edge detector = derivative of Gaussian filter, combines smoothing and gradient response.\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://upload.wikimedia.org/wikipedia/commons/c/c1/Wiki_slope_in_2d.svg\" width=250 height=150>\n",
    "\n",
    "(Image Source: Wikipedia)\n",
    "\n",
    "<img style=\"float: left;\" src=\"https://pic2.zhimg.com/v2-aad2460de5edbb636b1028e47957c5e1_b.webp\" width=250 height=150>\n",
    "\n",
    "(Image Source: These images appears in many places, including [here](https://pic2.zhimg.com/v2-aad2460de5edbb636b1028e47957c5e1_b.webp))\n",
    "\n",
    "<img style=\"float: ;\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/23ae6772c5f58751fc6014b71d6adafb30a31c79\" width=200 height=100>\n",
    "\n",
    "<img style=\"float: ;\" src=\"https://img-blog.csdnimg.cn/20200625014247541.png\" width=200 height=200>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X-Direction Kernel (Vertical)\n",
    "sobel_kernel_x = np.array([[1,0,-1], [2,0,-2], [1,0,-1]])\n",
    "# Y-Direction Kernel (Horizontal)\n",
    "sobel_kernel_y = np.array([[1,2,1], [0,0,0], [-1,-2,-1]])\n",
    "\n",
    "# Use Sobel filter to approximate the derivative of gaussian (for both x and y)\n",
    "dx = cv2.filter2D(org_img,-1,sobel_kernel_x)\n",
    "dy = cv2.filter2D(org_img,-1,sobel_kernel_y)\n",
    "\n",
    "magnitude = np.hypot(dx, dy)   # equivalent to sqrt(x1**2 + x2**2), element-wise\n",
    " \n",
    "angle = np.arctan2(dy, dx)     # Element-wise arc tangent of dy/dx \n",
    "\n",
    "fig,axs = plt.subplots(1,3)\n",
    "fig.set_figwidth(15)\n",
    "fig.set_figheight(15)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(dx,cmap='gray') \n",
    "plt.title('Derivative in x')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(dy,cmap='gray') \n",
    "plt.title('Derivative in y')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(magnitude,cmap=  'gray') \n",
    "plt.title('Magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Non-maximum Suppression of Edges (fill the code for diagonal directions)\n",
    "- Bin edges by orientation\n",
    "- For each edge pixel:\n",
    "    - Check the two neighbour pixels orthogonal to this edge pixel\n",
    "    - If either neighbour has same edge orientation AND higher magnitude, this pixel is not an edge\n",
    "    \n",
    "<img style=\"float: left;\" src=\"https://raw.githubusercontent.com/saraao/COMP90086_image/main/zone.jpg\" width=350 height=350>\n",
    "\n",
    "(Image Source: Jiayang)\n",
    "\n",
    "<img style=\"float: right;\" src=\"https://i0.wp.com/theailearner.com/wp-content/uploads/2019/05/Grad_direc-2.png?w=713&ssl=1\" width=350 height=350>\n",
    "\n",
    "(Image Source: These images appears in many places, including [here](https://i0.wp.com/theailearner.com/wp-content/uploads/2019/05/Grad_direc-2.png?w=713&ssl=1))\n",
    "\n",
    "<img style=\"float: left;\" src=\"https://docs.opencv.org/3.4/nms.jpg\" width=500 height=500>\n",
    "(Image Source: OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_maximum_suppression(magnitude,angle):\n",
    "    \n",
    "    size = magnitude.shape\n",
    "    result = np.zeros_like(magnitude) #Return an array of zeros with the same shape and type as a given array.\n",
    "\n",
    "    angle = np.rad2deg(angle) + 180    # Convert angle from radians to degrees.\n",
    "\n",
    "    \n",
    "    for i in range(1, size[0]-1):         # row,    vertical\n",
    "        for j in range(1, size[1]-1):     # column, horizontal\n",
    "            \n",
    "            # round the angle to one of four angles representing: \n",
    "            # 1 * horizontal, 2 * diagonal (45 degrees and 135 degrees), 1 * vertical directions.\n",
    "            \n",
    "            # horizontal\n",
    "            if 157.5 <= angle[i,j] < 202.5 or 0 <= angle[i,j] < 22.5 or 337.5 <= angle[i,j] <= 360:\n",
    "                p1 = magnitude[i,j-1]  # left\n",
    "                p2 = magnitude[i,j+1]  # right\n",
    "                \n",
    "            # vertical\n",
    "            elif 67.5 <= angle[i,j] < 112.5 or 247.5 <= angle[i,j] < 292.5:\n",
    "                p1 = magnitude[i+1,j]  # upper\n",
    "                p2 = magnitude[i-1,j]  # lower\n",
    "            \n",
    "            # 45 degrees\n",
    "            ## your code\n",
    "                \n",
    "            # 135 degrees\n",
    "            ## your code\n",
    "            \n",
    "            # Update the result only if one neighbour has same edge orientation (done above) AND higher magnitude\n",
    "            if magnitude[i,j] >= p1 and magnitude[i,j] >= p2:\n",
    "                result[i,j] = magnitude[i,j]\n",
    "                \n",
    "    return result \n",
    "\n",
    "magnitude_nms = non_maximum_suppression(magnitude,angle)\n",
    "# magnitude_nms = np.uint32(magnitude_nms)    # The gradient values might be very large - they should not overflow\n",
    "\n",
    "fig,axs = plt.subplots(1,2)\n",
    "fig.set_figwidth(18)\n",
    "fig.set_figheight(18)\n",
    "\n",
    "# plt will normalize the magnitude to [0, 255]\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(magnitude, cmap='gray') \n",
    "plt.title('Orginal magnitude')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(magnitude_nms, cmap='gray') \n",
    "plt.title('After non maximum suppression')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hysteresis Thresholding\n",
    "\n",
    "- Two thresholds T<sub>1</sub>, T<sub>2</sub>, with T<sub>1</sub> > T<sub>2</sub>\n",
    "- Strong edges: magnitude > T<sub>1</sub>\n",
    "- Weak edges: T<sub>1</sub> > magnitude > T<sub>2</sub>\n",
    "- For each weak edge:\n",
    "    - Check the 8-pixel neighbourhood around this pixel\n",
    "    - If any neighbour is a strong edge, relabel the weak edge pixel as a strong edge\n",
    "- Final edge map = strong edges\n",
    "\n",
    "<img style=\"float: ;\" src=\"https://docs.opencv.org/3.4/hysteresis.jpg\" width=500 height=500>\n",
    "\n",
    "(Image Source: OpenCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit   # Measure execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_threshold(magnitude, low_threshold=50, high_threshold=200):\n",
    "    \n",
    "    size = magnitude.shape\n",
    "    result = np.zeros_like(magnitude)\n",
    " \n",
    "    strong_edge_value = np.int32(255)     # int32 will resolve overflow issue of gredients\n",
    "    \n",
    "    strong_edges_x, strong_edges_y = np.where(magnitude >= high_threshold)\n",
    "    non_edges_x, non_edges_y = np.where(magnitude <= low_threshold)\n",
    "    \n",
    "    result[strong_edges_x, strong_edges_y] = strong_edge_value\n",
    "    \n",
    "    weak_edge_x, weak_edge_y = np.where((magnitude < high_threshold) & (magnitude > low_threshold))\n",
    "    \n",
    "    # We need to repeat this for several times, as some weak edges are relabeled as strong egdes during each iteration\n",
    "    for _ in range(2):    \n",
    "        for i in range(len(weak_edge_x)):\n",
    "            x,y = weak_edge_x[i], weak_edge_y[i]\n",
    "            # check 8-pixel neighbourhood around this pixel\n",
    "            if result[x+1,y] == strong_edge_value or result[x+1,y+1] == strong_edge_value or \\\n",
    "            result[x+1,y-1] == strong_edge_value or result[x-1,y] == strong_edge_value or result[x-1,y+1] == strong_edge_value or \\\n",
    "            result[x-1,y-1] == strong_edge_value or result[x,y+1] == strong_edge_value or result[x,y-1] == strong_edge_value:\n",
    "                 result[x, y] = strong_edge_value\n",
    "\n",
    "        for i in reversed(range(len(weak_edge_x))):\n",
    "            x,y = weak_edge_x[i], weak_edge_y[i]\n",
    "            # check 8-pixel neighbourhood around this pixel\n",
    "            if result[x+1,y] == strong_edge_value or result[x+1,y+1] == strong_edge_value or \\\n",
    "            result[x+1,y-1] == strong_edge_value or result[x-1,y] == strong_edge_value or result[x-1,y+1] == strong_edge_value or \\\n",
    "            result[x-1,y-1] == strong_edge_value or result[x,y+1] == strong_edge_value or result[x,y-1] == strong_edge_value:\n",
    "                 result[x, y] = strong_edge_value\n",
    "\n",
    "    return result\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "final_res = hysteresis_threshold(magnitude_nms, 50, 196)\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "fig,axs = plt.subplots(1,2)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(magnitude_nms,cmap='gray') \n",
    "plt.title('After non maximum suppression')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(final_res,cmap='gray') \n",
    "plt.title('Final result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools \n",
    "# Functions creating iterators for efficient looping\n",
    "OFFSETS = list(itertools.product([-1, 0, 1], [-1, 0, 1]))\n",
    "OFFSETS.remove((0, 0))\n",
    "# OFFSETS = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "\n",
    "def hysteresis_threshold(magnitude, low_threshold=50, high_threshold=200):\n",
    "    \n",
    "    size = magnitude.shape\n",
    "    result = np.zeros_like(magnitude)\n",
    "    \n",
    "    strong_edge_value = np.int32(255)\n",
    "    weak_edge_value = np.int32(low_threshold)\n",
    "    \n",
    "    strong_edges_x, strong_edges_y = np.where(magnitude >= high_threshold)\n",
    "    non_edges_x, non_edges_y = np.where(magnitude <= low_threshold)\n",
    "    \n",
    "    result[strong_edges_x, strong_edges_y] = strong_edge_value  # make all existing strong edges as 255\n",
    "    \n",
    "    weak_edge_x, weak_edge_y = np.where((magnitude < high_threshold) & (magnitude > low_threshold))\n",
    "    result[weak_edge_x, weak_edge_y] = weak_edge_value          # make all existing strong edges as the low threshold (T_2)\n",
    "    \n",
    "    strong_num = len(strong_edges_x)\n",
    "    prev_strong_num = 0\n",
    "   \n",
    "    while(strong_num != prev_strong_num): # find all weak edges until the number does not change\n",
    "        prev_strong_num = strong_num\n",
    "        weak_edge_x, weak_edge_y = np.where(result == weak_edge_value)\n",
    "\n",
    "        for i in range(len(weak_edge_x)):\n",
    "            x,y = weak_edge_x[i], weak_edge_y[i]\n",
    "            # check 8-pixel neighbourhood around this pixel\n",
    "            has_strong_edge = False\n",
    "            for offset_x, offset_y in OFFSETS:\n",
    "                if result[x+offset_x, y+offset_y] == strong_edge_value:\n",
    "                    has_strong_edge = True         \n",
    "            if has_strong_edge:\n",
    "                result[x, y] = strong_edge_value\n",
    "                strong_num += 1\n",
    "    \n",
    "    weak_edge_x, weak_edge_y = np.where(result == weak_edge_value)\n",
    "    result[weak_edge_x, weak_edge_y] = 0\n",
    " \n",
    "    return result\n",
    "\n",
    "start = timeit.default_timer()\n",
    "\n",
    "final_res = hysteresis_threshold(magnitude_nms, 50, 196) \n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)\n",
    "\n",
    "fig,axs = plt.subplots(1,2)\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(20)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(magnitude_nms,cmap='gray') \n",
    "plt.title('After non maximum suppression')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(final_res,cmap='gray') \n",
    "plt.title('Final result')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of Canny Edge Detection algorithm can be broken down to multi-stage:\n",
    "\n",
    "- 1.Apply Gaussian filter to smooth the image in order to remove the noise\n",
    "\n",
    "- 2.Find edge magnitute and direction (Gradient Calculation)\n",
    "\n",
    "- 3.Apply Non-Maximum Suppression to thin the edges\n",
    "\n",
    "- 4.Apply Hysteresis Thresholding to find \"really edges\" and further reduce the noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Canny edge detection with OpenCV\n",
    "- Conduct experiments with the built-in Canny function in opencv to see the effect of changing the thresholds and the scale (=apertureSize)\n",
    "\n",
    "See: https://docs.opencv.org/4.6.0/da/d22/tutorial_py_canny.html\n",
    "\n",
    "[cv.Canny](https://docs.opencv.org/4.x/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de) (image, threshold1, threshold2[, edges[, apertureSize[, L2gradient]]]\t) \n",
    "\n",
    "Parameters\n",
    "\n",
    "- image:\t8-bit input image.\n",
    "\n",
    "- edges:\toutput edge map; single channels 8-bit image, which has the same size as image.\n",
    "\n",
    "- threshold1:\tfirst threshold for the hysteresis procedure.\n",
    "\n",
    "- threshold2:\tsecond threshold for the hysteresis procedure.\n",
    "\n",
    "- apertureSize:\taperture size for the Sobel operator. By default it is 3.\n",
    "\n",
    "- L2gradient: a flag, indicating whether a more accurate should be used to calculate the image gradient magnitude\n",
    "\n",
    "L2gradient (By default, it is False):\n",
    "\n",
    "- If True, it uses the equation mentioned above which is more accurate\n",
    "\n",
    "- If False, it uses this function: Edge_Gradient(G)=|Gx|+|Gy|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify softare for the next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    " \n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
