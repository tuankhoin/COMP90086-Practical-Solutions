{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP90086 Workshop 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop, you will have some practice of spatial filtering and frequency filtering on images.\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "- Spatial Filtering\n",
    "    - Standard filtering: blur, sharpen and edges\n",
    "    - Cross-correlation vs. Convolution\n",
    "    - Derivative of Gaussian\n",
    "    - Handle border effect\n",
    "   \n",
    "- Frequency Filtering\n",
    "    - Fourier transformation\n",
    "    - Swap magnitude/phase\n",
    "    - Fourier transform a filter \n",
    "    - Gaussian lowpass filter in the frequency domain\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Standard filtering: blur, sharpen and edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2  \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in an image from a filepath as graycsale.\n",
    "rootpath='./'\n",
    "img= cv2.imread(os.path.join(rootpath, \"img1.png\"),cv2.IMREAD_GRAYSCALE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cv2.filter2D( ) operation convolve a kernel with an image.\n",
    "\n",
    "[filter2D(src, ddepth, kernel)](https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html#ga27c049795ce870216ddfb366086b5a04)\n",
    "\n",
    "The filter2D(  )function requires three input arguments:\n",
    "\n",
    "- The first argument is the source image.\n",
    "\n",
    "- The second argument is ddepth, which indicates the depth of the resulting image. A value of -1 indicates that the final image will also have the same depth as the source image.\n",
    "\n",
    "- The final input argument is the kernel, which we apply to the source image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average filter\n",
    "avg_kernel = np.ones((15,15),np.float32)/225\n",
    "avg_out = cv2.filter2D(img,-1,avg_kernel)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img,cmap='gray') \n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(avg_out,cmap='gray') \n",
    "plt.title('Average out')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian filter\n",
    "\n",
    "[cv2.getGaussianKernel(ksize, sigma)](https://docs.opencv.org/4.5.2/d4/d86/group__imgproc__filter.html#gac05a120c1ae92a6060dd0db190a61afa)\n",
    "- ksize - kernel size, should be odd and positive (3,5,...)\n",
    "- sigma - Gaussian standard deviation. \n",
    "\n",
    "[np.outer(a, b, out=None)](https://numpy.org/doc/stable/reference/generated/numpy.outer.html)\n",
    "- Compute the outer product of two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter size 15\n",
    "\n",
    "# 1d gaussian kernel (size, sigma)\n",
    "gau_kernel = cv2.getGaussianKernel(15,5)\n",
    "\n",
    "gau_kern2d = np.outer(gau_kernel, gau_kernel)\n",
    "gau_kern2d=gau_kern2d/gau_kern2d.sum()\n",
    "gau_out = cv2.filter2D(img,-1,gau_kern2d)\n",
    "    \n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(gau_kern2d,cmap='gray' )\n",
    "plt.title('Gaussian kernel')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gau_out,cmap='gray') \n",
    "plt.title('Gaussian out')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shapen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])  \n",
    "shap_kernel_alt = np.array([[0,-1,0], [-1,5,-1], [0,-1,0]])  \n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(shap_kernel, cmap='gray') \n",
    "plt.title('Kernel')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(shap_kernel_alt, cmap='gray') \n",
    "plt.title('Kernel Alt')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapen_out= cv2.filter2D(img, -1, shap_kernel)\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img,cmap='gray') \n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(shapen_out,cmap='gray') \n",
    "plt.title('Shapen out')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel Edge Detection\n",
    "\n",
    "# edge_out_y3= cv2.Sobel(img,cv2.CV_8U,dx=1,dy=0,ksize=3)\n",
    "# edge_out_x3= cv2.Sobel(img,cv2.CV_8U,dx=0,dy=1,ksize=3)\n",
    "\n",
    "# X-Direction Kernel (Vertical)\n",
    "sobel_kernel_x =  np.array([[1,0,-1], [2,0,-2], [1,0,-1]])\n",
    "# Y-Direction Kernel (Horizontal)\n",
    "sobel_kernel_y =  np.array([[1,2,1], [0,0,0], [-1,-2,-1]])   \n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(sobel_kernel_x,cmap='gray') \n",
    "plt.title('Kernel (Vertical)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(sobel_kernel_y,cmap='gray') \n",
    "plt.title('Kernel (Horizontal)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the syntax for applying Sobel edge detection using OpenCV:\n",
    "\n",
    "[cv2.Sobel(src, ddepth, dx, dy)](https://docs.opencv.org/3.4/d4/d86/group__imgproc__filter.html#gacea54f142e81b6758cb6f375ce782c8d)\n",
    "    \n",
    "- ddepth is the depth of the destination image \n",
    "- dx is Horizontal sobel derivative \n",
    "- dy is vertical sobel derivative\n",
    "- ksize is the kernel size.\n",
    "\n",
    "The parameter ddepth specifies the precision of the output image, while dx and dy specify the order of the derivative in each direction. For example:\n",
    "- If dx=1 and dy=0, we compute the 1st derivative Sobel image in the x-direction.\n",
    "\n",
    "If both dx=1 and dy=1, we compute the 1st derivative Sobel image in both directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_out_x = cv2.filter2D(img,-1,sobel_kernel_x)\n",
    "sobel_out_y = cv2.filter2D(img,-1,sobel_kernel_y)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "#the figure has 1 row, 3 columns, and this plot is the first plot.\n",
    "plt.imshow(img,cmap='gray') \n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "#the figure has 1 row, 3 columns, and this plot is the second plot.\n",
    "plt.imshow(sobel_out_x,cmap='gray') \n",
    "plt.title('vertical edges_s3')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,3,3)\n",
    "#the figure has 1 row, 2 columns, and this plot is the third plot.\n",
    "plt.imshow(sobel_out_y,cmap='gray') \n",
    "plt.title('horizontal edges_s3')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Cross-correlation vs. Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*double click on the image to find the link (source) to it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://glassboxmedicine.files.wordpress.com/2019/07/convgif.gif?w=616)\n",
    "\n",
    "(Image Source: This animation appears in many places, including [here](https://hackernoon.com/visualizing-parts-of-convolutional-neural-networks-using-keras-and-cats-5cc01b214e59))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=\"#4d79ff\" size=\"4\"> Cross-correlation vs. Convolution </font></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of cross-correlation](https://miro.medium.com/max/700/1*RhHoldDIzmca3ula71tkFg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of convolution](https://miro.medium.com/max/700/1*DJIJX1Adlo_DzKo63IBYSg.png)\n",
    "\n",
    "(Image Source: These images appears in many places, including [here](https://towardsdatascience.com/convolution-vs-correlation-af868b6b4fb5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.filter2D accutually does correlation\n",
    "#to compare convolution and correlation,we use scipy.signal, which contains both convolution and correlation\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "imgr= np.random.randint(255, size=(10,10),dtype=np.uint8) #random a small image\n",
    "\n",
    "plt.imshow(imgr,cmap='gray') \n",
    "plt.title('original image')\n",
    "plt.axis('off')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.signal.correlate2d( )](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.correlate2d.html): Cross-correlate two 2-dimensional arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian filter\n",
    "\n",
    "gau_kernel = cv2.getGaussianKernel(3,3)# 1d gaussian kernel (size, sigma)\n",
    "gau_kern2d = np.outer(gau_kernel, gau_kernel )\n",
    "gau_kern2d = gau_kern2d/gau_kern2d.sum()\n",
    "\n",
    "#gau_out_corr = cv2.filter2D(imgr,-1,gau_kern2d,borderType=cv2.BORDER_REFLECT) #correlation\n",
    "gau_out_corr = signal.correlate2d(imgr, gau_kern2d, boundary='symm', mode='same') #correlation\n",
    "\n",
    "#gau_kern2d_conv=np.flip(gau_kern2d)\n",
    "#gau_out_conv = cv2.filter2D(imgr,-1,gau_kern2d_conv)  \n",
    "gau_out_conv = signal.convolve2d(imgr, gau_kern2d, boundary='symm', mode='same') #convolution\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(imgr,cmap='gray') \n",
    "plt.title('original image')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(gau_out_conv,cmap='gray') \n",
    "plt.title('gau_convolution')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(gau_out_corr,cmap='gray') \n",
    "plt.title('gau_correlation')\n",
    "plt.axis('off') \n",
    "\n",
    "plt.show() # the kernel is symmetric, so the outputs are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_kernel =  np.array([[1,0,-1], [2,0,-2], [1,0,-1]])   \n",
    "#sobel_out_corr = cv2.filter2D(imgr,-1,sobel_kernel,borderType=cv2.BORDER_REFLECT)\n",
    "sobel_out_corr = signal.correlate2d(imgr, sobel_kernel, boundary='symm', mode='same') #correlation\n",
    "\n",
    "#sobel_kernel_conv = np.flip(sobel_kernel)\n",
    "#sobel_out_conv = cv2.filter2D(imgr,-1,sobel_kernel_conv)\n",
    "sobel_out_conv = signal.convolve2d(imgr, sobel_kernel, boundary='symm', mode='same') #convolution\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(imgr,cmap='gray') \n",
    "plt.title('original image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(sobel_out_conv,cmap='gray') \n",
    "plt.title('sobel_convolution')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(sobel_out_corr,cmap='gray') \n",
    "plt.title('sobel_correlation')\n",
    "plt.axis('off') \n",
    "\n",
    "plt.show() # the kernel is asymmetric, so the outputs are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Derivative of Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[np.gradient( )](https://numpy.org/doc/stable/reference/generated/numpy.gradient.html): Return the gradient of an N-dimensional array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use scipy.signal, which contains correlation\n",
    "from scipy import signal\n",
    "\n",
    "rootpath='./'\n",
    "img2= cv2.imread(os.path.join(rootpath, \"img2.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "gau_kernel = cv2.getGaussianKernel(3,1) # 1d gaussian kernel (size, sigma)\n",
    "gau_kern2d = np.outer(gau_kernel, gau_kernel)\n",
    "gau_kern2d=gau_kern2d/np.abs(gau_kern2d).sum()\n",
    "\n",
    "\n",
    "gau_out=signal.convolve2d(img2,gau_kern2d, boundary='symm', mode='same')\n",
    "\n",
    "#Return the gradient of an N-dimensional array.\n",
    "derivative_out1=np.gradient(gau_out,axis=1)\n",
    "\n",
    "#plt.subplot(): You can draw as many plots you like on one figure, \n",
    "#just descibe the number of rows, columns, and the index of the plot. \n",
    "#For example, Draw 6 plots in a figure with 2 row, 3 columns.\n",
    "#stacking in two directions （row, columns,the index of the plot）\n",
    "\n",
    "\n",
    "#Figure size in inches (default)\n",
    "plt.subplots(figsize=(5, 5)) \n",
    "\n",
    "plt.subplot(2,3,1)\n",
    "plt.imshow(img2,cmap='gray') \n",
    "plt.title('org')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,3,2)\n",
    "plt.imshow(gau_out,cmap='gray') \n",
    "plt.title('gau_out')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(2,3,3)\n",
    "plt.imshow(derivative_out1,cmap='gray') \n",
    "plt.title('derivative_out1')\n",
    "plt.axis('off') \n",
    "\n",
    "#The derivative of a Gaussian Process is also a Gaussian Process\n",
    "d_g=np.gradient(gau_kern2d,axis=1) \n",
    "derivative_out2=signal.convolve2d(img2,d_g, boundary='symm', mode='same')\n",
    "\n",
    "plt.subplot(2,3,4)\n",
    "plt.imshow(gau_kern2d,cmap='gray') \n",
    "plt.title('gau_kern2d')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(2,3,5)\n",
    "plt.imshow(d_g,cmap='gray') \n",
    "plt.title('d_g')\n",
    "plt.axis('off')\n",
    "\n",
    "\n",
    "plt.subplot(2,3,6)\n",
    "plt.imshow(derivative_out2,cmap='gray') \n",
    "plt.title('derivative_out2')\n",
    "plt.axis('off') \n",
    "\n",
    "plt.suptitle(\"Derivative of Gaussian\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Handle border effect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[borderType](https://docs.opencv.org/4.5.2/d2/de8/group__core__array.html#ga209f2f4869e304c82d07739337eae7c5): pixel extrapolation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= np.random.randint(255, size=(10,10),dtype=np.uint8) #random  a small image\n",
    "\n",
    "\n",
    "gau_kernel = cv2.getGaussianKernel(5,5)# 1d gaussian kernel (size, sigma)\n",
    "gau_kern2d = np.outer(gau_kernel, gau_kernel)\n",
    "gau_kern2d = gau_kern2d/gau_kern2d.sum()\n",
    "\n",
    "#Various border types, image boundaries are denoted with |\n",
    "gau_out1 = cv2.filter2D(img,-1,gau_kern2d, borderType = cv2.BORDER_CONSTANT ) #iiiiii|abcdefgh|iiiiiii\n",
    "gau_out2 = cv2.filter2D(img,-1,gau_kern2d, borderType =cv2.BORDER_REPLICATE) #aaaaaa|abcdefgh|hhhhhhh\n",
    "gau_out3 = cv2.filter2D(img,-1,gau_kern2d, borderType =cv2.BORDER_REFLECT) #fedcba|abcdefgh|hgfedcb\n",
    "\n",
    "plt.subplot(1,2,1)   \n",
    "plt.imshow(img ,cmap='gray')  \n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "                \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gau_out1,cmap='gray')  \n",
    "plt.title('constant')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(gau_out2,cmap='gray') \n",
    "plt.title('replicate')\n",
    "plt.axis('off')\n",
    "\n",
    " \n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gau_out3,cmap='gray') \n",
    "plt.title('reflect')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Fourier transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font color=\"#4d79ff\" size=\"4\">  Fourier series and transform <center></font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Fourier series and transform](https://upload.wikimedia.org/wikipedia/commons/2/2b/Fourier_series_and_transform.gif)\n",
    "\n",
    "(Image courtesy: [Wikipedia](https://en.wikipedia.org/wiki/Fourier_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath='./'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took an image, we decompose it into magnitude and phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_image(img):\n",
    "    # Fast Fourier transform\n",
    "    f = np.fft.fft2(img)\n",
    "    \n",
    "    # Shift the low frequency component to the center\n",
    "    f = np.fft.fftshift(f)\n",
    "\n",
    "    # Fourier phase and magnitude\n",
    "    phase = np.angle(f)\n",
    "    magnitude = np.abs(f)\n",
    "    \n",
    "    #Figure size in inches (default)\n",
    "    plt.subplots(figsize=(10, 10)) \n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(img ,cmap='gray')  \n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Phase\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(phase ,cmap='gray')  \n",
    "    plt.title('Phase')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Magnitude\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(magnitude ,cmap='gray')  \n",
    "    plt.title('Magnitude')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low frequencies in images: pixel values that are changing slowly.\n",
    "\n",
    "High frequencies in images mean pixel values that are changing dramatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(os.path.join(rootpath, \"F1.1.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've got a signal that's quite low frequency. It's only in the horizontal. So we've got a Fourier transform that's got just two little peaks representing the frequency of that sinusoid and there across the X, because it's only in the horizontal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.2.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have a higher frequency sinusoid. So we have slightly more spaced out dots. It's a higher frequency represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.3.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a diagonal sinusoid. So we've got the same dots, essentially the same frequency, but along the diagonal direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_image_log(img):\n",
    "    # Fourier transform\n",
    "    f = np.fft.fft2(img)\n",
    "    # Shift the low frequency component to the center\n",
    "    f = np.fft.fftshift(f)\n",
    "    \n",
    "    # Fourier phase and magnitude\n",
    "    phase = np.angle(f)\n",
    "    magnitude = np.abs(f)\n",
    "    # the orginal magnitute is too small, we show log of the value to make it clear\n",
    "    magnitude_log = np.log(np.abs(f))  \n",
    "    \n",
    "    #figure size\n",
    "    plt.subplots(figsize=(7, 7)) \n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(img ,cmap='gray')  \n",
    "    plt.title('image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Phase\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(phase ,cmap='gray')  \n",
    "    plt.title('phase')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # the orginal magnitude\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(magnitude ,cmap='gray')  \n",
    "    plt.title('magnitude')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # log of the orginal magnitude\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(magnitude_log ,cmap='gray')  \n",
    "    plt.title('log magnitude')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread(os.path.join(rootpath, \"F1.4.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.5.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line/stripe in magnitude corresponds to anything that's orthogonal to that in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.6.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've got little dots, so there's no vertical lines. There's no horizontal lines. It's just circles everywhere.\n",
    "\n",
    "And so you see this strong circular pattern. The period of the pattern is probably reflecting. Something about the the spacing of the dots are the size of the dots as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.7.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.8.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.9.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.10.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.11.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.12.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.13.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.14.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(os.path.join(rootpath, \"F1.15.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "FFT_image_log(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Swap magnitude/phase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1= cv2.imread(os.path.join(rootpath, \"f2.1.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "img1= cv2.resize(img1,(350,350))\n",
    "\n",
    "# Fourier transform\n",
    "f = np.fft.fft2(img1)\n",
    "# Shift the low frequency component to the center\n",
    "f = np.fft.fftshift(f)\n",
    "\n",
    "# Fourier phase and magnitude\n",
    "phase1 = np.angle(f)\n",
    "magnitude1 = np.abs(f)\n",
    "\n",
    "img2= cv2.imread(os.path.join(rootpath, \"f2.2.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "img2= cv2.resize(img2,(350,350))\n",
    "\n",
    "# Fourier transform\n",
    "f = np.fft.fft2(img2)\n",
    "f = np.fft.fftshift(f)\n",
    "\n",
    "# Fourier phase and magnitude\n",
    "phase2 = np.angle(f)\n",
    "magnitude2 = np.abs(f)\n",
    "\n",
    "phase1_mag2 = np.multiply(magnitude2, np.exp(1j*phase1))\n",
    "phase2_mag1 = np.multiply(magnitude1, np.exp(1j*phase2))\n",
    "\n",
    "# Invert Fourier transform to get images\n",
    "\n",
    "# im_phase1_mag2 = np.real(np.fft.ifft2(np.fft.fftshift(phase1_mag2)))\n",
    "# im_phase2_mag1 = np.real(np.fft.ifft2(np.fft.fftshift(phase2_mag1 )))\n",
    "\n",
    "# fftshift -> ifftshift\n",
    "\n",
    "# (Invert of FFT(Shift the low-frequency component back to original location))\n",
    "im_phase1_mag2 = np.real(np.fft.ifft2(np.fft.ifftshift(phase1_mag2)))\n",
    "im_phase2_mag1 = np.real(np.fft.ifft2(np.fft.ifftshift(phase2_mag1 )))\n",
    "\n",
    "\n",
    "#Figure size\n",
    "plt.subplots(figsize=(7, 7)) \n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(img1 ,cmap='gray')  \n",
    "plt.title('image1')\n",
    "plt.axis('off')\n",
    " \n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(img2 ,cmap='gray')  \n",
    "plt.title('image2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(im_phase1_mag2, cmap='gray')  \n",
    "plt.title('im_phase1_mag2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(im_phase2_mag1 ,cmap='gray')  \n",
    "plt.title('im_phase2_mag1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#What aspects of the image are captured by the magnitude and the phase of the FT? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Fourier transform a filter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution in spatial domain = multiplication in Fourier domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian filter size 15\n",
    " \n",
    "gau_kernel = cv2.getGaussianKernel(15,5)# 1d gaussian kernel (size, sigma)\n",
    "gau_kern2d = np.outer(gau_kernel, gau_kernel)\n",
    "gau_kern2d=gau_kern2d/gau_kern2d.sum()\n",
    "  \n",
    "# Fourier transform\n",
    "f = np.fft.fft2(gau_kern2d)\n",
    "# Shift the low frequency component to the center\n",
    "f = np.fft.fftshift(f)\n",
    "\n",
    "# Fourier phase and magnitude\n",
    "phase = np.angle(f)\n",
    "magnitude = np.abs(f)\n",
    "\n",
    "plt.subplots(figsize=(10, 10)) \n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(gau_kern2d ,cmap='gray')  \n",
    "plt.title('image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(phase ,cmap='gray')  \n",
    "plt.title('phase')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(magnitude ,cmap='gray')  \n",
    "plt.title('magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gau_kern2d=np.gradient(gau_kern2d,axis=0)\n",
    "\n",
    "# Fourier transform\n",
    "f = np.fft.fft2(gau_kern2d)\n",
    "# Shift the low frequency component to the center\n",
    "f = np.fft.fftshift(f)\n",
    "\n",
    "# Fourier phase and magnitude\n",
    "phase = np.angle(f)\n",
    "magnitude = np.abs(f)\n",
    "\n",
    "             \n",
    "plt.subplots(figsize=(10, 10)) \n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(gau_kern2d ,cmap='gray')  \n",
    "plt.title('image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(phase ,cmap='gray')  \n",
    "plt.title('phase')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(magnitude ,cmap='gray')  \n",
    "plt.title('magnitude')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bandpass filter\n",
    "\n",
    "Bandpass filter = a filter that removes a range of frequencies from a signal\n",
    "\n",
    "Low pass filter = keep low spatial frequencies, remove high frequencies\n",
    "\n",
    "High pass filter = keep high spatial frequencies, remove low frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## (4) Gaussian lowpass filter in the frequency domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_low = 10\n",
    "\n",
    "rootpath='./'\n",
    "img= cv2.imread(os.path.join(rootpath, \"f1.5.png\"),cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    " \n",
    "# Fourier transform\n",
    "f = np.fft.fft2(img)\n",
    "# Shift the low frequency component to the center\n",
    "f = np.fft.fftshift(f)\n",
    "\n",
    "\n",
    "def Gauss_LowPass(f,radius_low):  \n",
    "#values are higher near the center, and close to zero outside        \n",
    "    \n",
    "    m = f.shape[0]\n",
    "    n = f.shape[1]\n",
    "    mask = np.zeros((m, n))\n",
    "  \n",
    "    x0 = np.floor(m/2)\n",
    "    y0 = np.floor(n/2)\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            dis = np.sqrt((i - x0)**2 + (j - y0)**2)\n",
    "            mask[i][j] = np.exp((-1)*dis**2/2/(radius_low**2))\n",
    "        \n",
    "    \n",
    "    result = np.multiply(f, mask) \n",
    "    return result,mask\n",
    "\n",
    " \n",
    "\n",
    "f_low_filtered,mask_low = Gauss_LowPass(f,radius_low)\n",
    "  \n",
    "\n",
    "# Invert Fourier transform to get the filtered image\n",
    "# (Invert of FFT(Shift the low-frequency component back to original location))\n",
    "\n",
    "# fftshift -> ifftshift\n",
    "img_low = np.real(np.fft.ifft2(np.fft.ifftshift(f_low_filtered)))\n",
    "\n",
    "\n",
    "plt.subplots(figsize=(10, 10)) \n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img ,cmap='gray')  \n",
    "plt.title('original image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_low ,cmap='gray')  \n",
    "plt.title('low out')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(mask_low ,cmap='gray')  \n",
    "plt.title('low mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Implement a 2D Gaussian blur using two 1D filters. Compare the running time with the 2D Gaussian filtering\n",
    "\n",
    "(2) Try varying the kernel size of Gaussian filter and see what changes. e.g., blur with a 5x5 Gaussian vs. a 15x15 Gaussian. \n",
    "\n",
    "(3) Take an image and \"delete\" its magnitude or phase by replacing it with random values. \n",
    "\n",
    "(4) implement a Gaussian highpass filter in the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
